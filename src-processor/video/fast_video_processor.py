#!/usr/bin/env python3
"""
Fast Video Processor - Versi√≥n Mejorada
Procesador de video optimizado con las mejoras de robustez de video_processes.py
"""

import cv2
import numpy as np
import time
import os
from typing import Dict, List, Optional, Tuple
from PySide6.QtCore import QThread, Signal

try:
    from numba import jit, prange
    NUMBA_AVAILABLE = True
    print("Numba disponible - usando optimizaciones")
except ImportError:
    NUMBA_AVAILABLE = False
    print("Numba no disponible - usando implementaci√≥n est√°ndar")

try:
    from ultralytics import YOLO
    import torch
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    print("YOLO no disponible - verificar instalaci√≥n de ultralytics")


def get_model_file_path(model_name):
    """Obtener ruta del modelo YOLO"""
    possible_paths = [
        f"models/{model_name}",
        f"src/models/{model_name}", 
        f"src-processor/models/{model_name}", 
        f"utils/models/{model_name}",
        f"data/models/{model_name}",
        model_name
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return path
    
    print(f"Modelo {model_name} no encontrado en rutas: {possible_paths}")
    return None


# Funciones aceleradas con Numba si est√° disponible
if NUMBA_AVAILABLE:
    @jit(nopython=True, cache=True)
    def apply_threshold_fast(gray_region, threshold):
        """Aplicar umbral r√°pido con Numba"""
        h, w = gray_region.shape
        result = np.zeros((h, w), dtype=np.uint8)
        
        for i in prange(h):
            for j in prange(w):
                if gray_region[i, j] < threshold:
                    result[i, j] = 255
                else:
                    result[i, j] = 0
                    
        return result
    
    @jit(nopython=True, cache=True)
    def calculate_distances_fast(contour_points, center_x, center_y):
        """Calcular distancias de puntos al centro con Numba"""
        n = len(contour_points)
        distances = np.zeros(n)
        
        for i in range(n):
            dx = contour_points[i][0] - center_x
            dy = contour_points[i][1] - center_y
            distances[i] = np.sqrt(dx*dx + dy*dy)
            
        return distances
else:
    def apply_threshold_fast(gray_region, threshold):
        """Versi√≥n est√°ndar sin Numba"""
        return cv2.threshold(gray_region, threshold, 255, cv2.THRESH_BINARY_INV)[1]
    
    def calculate_distances_fast(contour_points, center_x, center_y):
        """Versi√≥n est√°ndar sin Numba"""
        dx = contour_points[:, 0] - center_x
        dy = contour_points[:, 1] - center_y
        return np.sqrt(dx*dx + dy*dy)


class FastVideoProcessor:
    """
    Procesador de video optimizado con mejoras de robustez de video_processes.py
    """
    
    def __init__(self, thresholds: Dict):
        self.thresholds = thresholds
        self.model = None
        self.setup_yolo_model()
        
        # Cache para optimizaci√≥n
        self.last_detections = []
        self.detection_counter = 0
        self.detection_frequency = 4  # Detectar cada 4 frames
        
        # Configuraci√≥n de visualizaci√≥n
        self.show_yolo_detection = True
        self.show_masks = True
        self.show_pupil_point = True
        self.show_parameters = True
        
        
        # Cache del √∫ltimo valor v√°lido para parpadeos
        self.last_valid_pupil_x = 0.0
        self.last_valid_pupil_y = 0.0
        self.last_valid_radius = 0.0

    def setup_yolo_model(self):
        """Configurar modelo YOLO para detecci√≥n de ojos"""
        if not YOLO_AVAILABLE:
            print("YOLO no disponible - no se puede cargar modelo")
            return
            
        try:
            model_path = get_model_file_path('siev_vng_r01.pt')
            if model_path is None:
                print("No se encontr√≥ el modelo YOLO")
                return
                
            self.model = YOLO(model_path)
            
           # Optimizaciones para CPU/GPU (solo la primera vez)
            try:
                if not torch.cuda.is_available():
                    torch.set_num_threads(1)
                    torch.set_num_interop_threads(1)
                    print("Usando CPU para YOLO")
                else:
                    print("Usando GPU para YOLO")
            except RuntimeError as e:
                # Ya est√° configurado, ignorar
                print(f"PyTorch ya configurado previamente: {e}")
                
            print(f"Modelo YOLO cargado desde: {model_path}")
            
        except Exception as e:
            print(f"Error cargando modelo YOLO: {e}")
            self.model = None
            
    def process_frame(self, frame: np.ndarray) -> Tuple[float, float, bool, np.ndarray]:
        #print(f"üü¶ === INICIO process_frame ===")
        #print(f"üü¶ L√≠nea 1: frame type = {type(frame)}")
        #print(f"üü¶ L√≠nea 2: frame shape = {frame.shape if frame is not None else 'None'}")
        #print(f"üü¶ L√≠nea 3: model = {self.model is not None}")
        """
        Procesar frame y retornar posici√≥n de pupila del ojo derecho con visualizaci√≥n
        
        Returns:
            Tuple[x, y, detected, visualization_frame]: Posici√≥n x, y, si se detect√≥ y frame con visualizaci√≥n
        """
        
        #print(f"üü¶ L√≠nea 4: Despu√©s del docstring")
        
        if frame is None or self.model is None:
            #print("="*50)
            #print(f"EARLY RETURN DEBUG:")
            #print(f"frame is None: {frame is None}")
            #print(f"model is None: {self.model is None}")
            #print("="*50)
            return 0.0, 0.0, False, frame if frame is not None else np.zeros((480, 640, 3), dtype=np.uint8)
            
        #print(f"üü¶ L√≠nea 5: Pas√≥ el if inicial")
                    
        try:
            #print(f"üü¶ L√≠nea 6: Entrando al try")

            # Hacer copia para visualizaci√≥n
            vis_frame = frame.copy()
            #print(f"üü¶ L√≠nea 7: vis_frame creado")

            h, w = frame.shape[:2]
            #print(f"üü¶ L√≠nea 8: Llamando _detect_eyes_yolo")

            # Detectar ojos con YOLO (con cache para optimizar)
            detections = self._detect_eyes_yolo(frame)
            #print(f"üü¶ L√≠nea 9: _detect_eyes_yolo retorn√≥: {len(detections) if detections else 0} detections")

            if not detections:
                #print(f"üî¥ YOLO fall√≥, last_valid_pupil_x = {self.last_valid_pupil_x} (deber√≠a ser 41.0)")
                self._draw_no_detection_info(vis_frame, "No se detectaron ojos con YOLO")
                return_value = self.last_valid_pupil_x, self.last_valid_pupil_y, False, vis_frame
                #print(f"üî¥ Retornando: {return_value[0]}, {return_value[1]}")
                return return_value
                
            # Buscar ojo derecho (el de la izquierda en la imagen, menor x)
            right_eye_detection = self._find_right_eye(detections, w)
            
            if right_eye_detection is None:
                #print(f"üî¥ No right eye, last_valid_pupil_x = {self.last_valid_pupil_x}")
                self._draw_no_detection_info(vis_frame, "No se identific√≥ ojo derecho v√°lido")
                return_value = self.last_valid_pupil_x, self.last_valid_pupil_y, False, vis_frame
                #print(f"üî¥ Retornando: {return_value[0]}, {return_value[1]}")
                return return_value
                
            # Dibujar detecci√≥n YOLO
            if self.show_yolo_detection:
                self._draw_yolo_detection(vis_frame, right_eye_detection)
                
            # Procesar regi√≥n del ojo derecho
            pupil_x, pupil_y, radius, masks = self._process_eye_region_improved(frame, right_eye_detection)
            
            # Dibujar m√°scaras y pupila
            if self.show_masks and masks:
                self._draw_eye_masks(vis_frame, right_eye_detection, masks)
                
            if self.show_pupil_point and pupil_x > 0 and pupil_y > 0:
                self._draw_pupil_detection_improved(vis_frame, right_eye_detection, pupil_x, pupil_y, radius)
            
            # Mostrar par√°metros
            if self.show_parameters:
                pass
                #self._draw_parameters_info(vis_frame)
            
            # Actualizar cache solo si se detect√≥ correctamente
            if pupil_x > 0 and pupil_y > 0:
                #print(f"ACTUALIZANDO last_valid: de {self.last_valid_pupil_x} a {pupil_x}")
                if pupil_x > 5.0:
                    old_value = self.last_valid_pupil_x  # Guardar valor anterior
                    self.last_valid_pupil_x = pupil_x
                    #print(f"üü¢ CONFIRMADO: last_valid_pupil_x cambi√≥ de {old_value} a {self.last_valid_pupil_x}")
    
            return pupil_x, pupil_y, True, vis_frame
            
        except Exception as e:
            #print(f"üî¥ EXCEPCI√ìN CAPTURADA: {e}")
            #print(f"Error procesando frame: {e}")
            self._draw_error_info(vis_frame, str(e))
            return 0.0, 0.0, False, vis_frame  # ‚Üê ¬°AQU√ç EST√Å EL 0.0!
            
    def _detect_eyes_yolo(self, frame: np.ndarray) -> List[Dict]:
        """Detectar ojos usando YOLO con cache para optimizaci√≥n"""
        self.detection_counter += 1
        
        # Solo ejecutar YOLO cada N frames para optimizar
        if self.detection_counter % self.detection_frequency == 0 or not self.last_detections:
            try:
                # Escalar frame para YOLO (m√°s r√°pido con imagen m√°s peque√±a)
                scale_factor = 0.5
                scaled_frame = cv2.resize(frame, None, fx=scale_factor, fy=scale_factor)
                
                # Ejecutar detecci√≥n YOLO
                results = self.model(
                    scaled_frame,
                    conf=0.5,      # Umbral de confianza
                    iou=0.45,      # Umbral IOU para NMS
                    verbose=False, # Sin mensajes de debug
                    max_det=2      # M√°ximo 2 detecciones (ojos)
                )
                
                detections = []
                if results and len(results) > 0:
                    boxes = results[0].boxes
                    if boxes is not None:
                        for box in boxes:
                            # Convertir coordenadas de vuelta a escala original
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            x1, y1, x2, y2 = x1/scale_factor, y1/scale_factor, x2/scale_factor, y2/scale_factor
                            
                            conf = box.conf[0].cpu().numpy()
                            
                            detections.append({
                                'x1': int(x1), 'y1': int(y1),
                                'x2': int(x2), 'y2': int(y2),
                                'conf': float(conf),
                                'cx': int((x1 + x2) / 2),
                                'cy': int((y1 + y2) / 2),
                                'w': int(x2 - x1),
                                'h': int(y2 - y1)
                            })
                
                self.last_detections = detections
                
            except Exception as e:
                print(f"Error en detecci√≥n YOLO: {e}")
                return self.last_detections
                
        return self.last_detections
        
    def _find_right_eye(self, detections: List[Dict], frame_width: int) -> Optional[Dict]:
        # Solo procesar ojos en la mitad IZQUIERDA de la imagen (ojo derecho del sujeto)
        frame_center_x = frame_width / 2
        valid_detections = []

        for det in detections:
            # Si el centro del ojo est√° en la mitad izquierda, es v√°lido
            if det['cx'] < frame_center_x:
                valid_detections.append(det)

        if not valid_detections:
            return None

        # Si hay m√∫ltiples ojos v√°lidos, tomar el de menor x
        return min(valid_detections, key=lambda det: det['cx'])
        
    def _process_eye_region_improved(self, frame: np.ndarray, eye_detection: Dict) -> Tuple[float, float, float, List]:
        """
        Procesar regi√≥n del ojo con las mejoras de video_processes.py
        """
        masks = []
        
        try:
            # Extraer ROI del ojo
            x1, y1, x2, y2 = eye_detection['x1'], eye_detection['y1'], eye_detection['x2'], eye_detection['y2']
            eye_region = frame[y1:y2, x1:x2]
            
            if eye_region.size == 0:
                return 0.0, 0.0, 0.0, masks
                
            # Convertir a escala de grises
            if len(eye_region.shape) == 3:
                eye_gray = cv2.cvtColor(eye_region, cv2.COLOR_BGR2GRAY)
            else:
                eye_gray = eye_region.copy()
                
            # Dimensiones del ojo
            ew, eh = eye_region.shape[1], eye_region.shape[0]
                
            # 1. PREPROCESAMIENTO OPTIMIZADO (igual que video_processes.py)
            blurred = cv2.GaussianBlur(eye_gray, (5, 5), 0)
            
            # Mejorar contraste con CLAHE
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            enhanced = clahe.apply(blurred)
            
            # 2. UMBRAL MEJORADO (con opci√≥n OTSU como en video_processes.py)
            threshold_value = self.thresholds.get('threshold_right', 50)
            
            if threshold_value == 0:
                # Usar OTSU adaptativo cuando threshold es 0
                otsu_thresh, _ = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
                adjusted_thresh = max(0, min(255, otsu_thresh + threshold_value))
                _, thresh = cv2.threshold(enhanced, adjusted_thresh, 255, cv2.THRESH_BINARY_INV)
            else:
                # Umbral fijo
                if NUMBA_AVAILABLE:
                    thresh = apply_threshold_fast(enhanced, threshold_value)
                else:
                    _, thresh = cv2.threshold(enhanced, threshold_value, 255, cv2.THRESH_BINARY_INV)
                    
            masks.append((thresh, (255, 255, 0), f"THRESHOLD {threshold_value}"))  # Amarillo
            
            # 3. OPERACIONES MORFOL√ìGICAS MEJORADAS (igual que video_processes.py)
            kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            
            # Aplicar erosi√≥n si es necesario
            erode_value = self.thresholds.get('erode_right', 2)
            if erode_value > 0:
                thresh_eroded = cv2.erode(thresh, kernel_small, iterations=erode_value)
                masks.append((thresh_eroded, (0, 255, 255), f"ERODE {erode_value}"))  # Cian
            else:
                thresh_eroded = thresh
                
            # Cerrar para eliminar peque√±os huecos
            thresh_closed = cv2.morphologyEx(thresh_eroded, cv2.MORPH_CLOSE, kernel_small, iterations=1)
            
            # Dilatar ligeramente para capturar toda la pupila
            thresh_processed = cv2.dilate(thresh_closed, kernel_small, iterations=1)
            
            masks.append((thresh_processed, (255, 0, 255), "PROCESSED"))  # Magenta
            
            # 4. ENCONTRAR CONTORNOS Y FILTRAR (MEJORADO)
            contours, _ = cv2.findContours(thresh_processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if not contours:
                return 0.0, 0.0, 0.0, masks
                
            # FILTRADO MEJORADO: √°rea m√≠nima Y M√ÅXIMA (como en video_processes.py)
            valid_contours = []
            for c in contours:
                area = cv2.contourArea(c)
                # La pupila no debe ser m√°s del 50% del ojo (importante!)
                if area > 20 and area < (ew * eh * 0.5):
                    valid_contours.append(c)
            
            if not valid_contours:
                return 0.0, 0.0, 0.0, masks
                
            # Ordenar por √°rea (mayor primero)
            valid_contours = sorted(valid_contours, key=cv2.contourArea, reverse=True)
            largest_contour = valid_contours[0]
            
            # 5. C√ÅLCULO ROBUSTO DEL CENTRO (como en video_processes.py)
            M = cv2.moments(largest_contour)
            if M["m00"] != 0:
                center_x = int(M["m10"] / M["m00"])
                center_y = int(M["m01"] / M["m00"])
            else:
                # Fallback si el momento falla
                x, y, w, h = cv2.boundingRect(largest_contour)
                center_x = x + w // 2
                center_y = y + h // 2
            
            # 6. ESTABILIZACI√ìN DEL RADIO (CR√çTICO - como en video_processes.py)
            # Calcular distancias de todos los puntos al centro
            contour_points = largest_contour.reshape(-1, 2)
            
            if NUMBA_AVAILABLE:
                distances = calculate_distances_fast(contour_points, center_x, center_y)
            else:
                # Versi√≥n vectorizada numpy
                dx = contour_points[:, 0] - center_x
                dy = contour_points[:, 1] - center_y
                distances = np.sqrt(dx*dx + dy*dy)
            
            # Usar MEDIANA para estabilidad (no media!)
            if len(distances) > 0:
                radius = int(np.median(distances))
            else:
                # Fallback
                (cx, cy), radius = cv2.minEnclosingCircle(largest_contour)
                radius = int(radius)
            
            # 7. LIMITAR CAMBIOS BRUSCOS EN EL RADIO (como en video_processes.py)
            min_radius = 5
            max_radius = min(ew, eh) // 3  # El radio no debe ser m√°s de 1/3 del ojo
            
            radius = max(min_radius, min(radius, max_radius))
            
            # Crear m√°scara del contorno final para visualizaci√≥n
            contour_mask = np.zeros_like(thresh_processed)
            cv2.drawContours(contour_mask, [largest_contour], 0, 255, -1)
            
            # Dibujar informaci√≥n en la m√°scara
            mask_viz = cv2.cvtColor(contour_mask, cv2.COLOR_GRAY2BGR)
            cv2.circle(mask_viz, (center_x, center_y), radius, (0, 255, 0), 1)
            cv2.circle(mask_viz, (center_x, center_y), 2, (255, 0, 0), -1)
            masks.append((mask_viz, (0, 0, 255), "PUPIL"))  # Rojo
            
            return float(center_x), float(center_y), float(radius), masks
            
        except Exception as e:
            print(f"Error en process_eye_region_improved: {e}")
            return 0.0, 0.0, 0.0, masks
            
    def _draw_yolo_detection(self, vis_frame: np.ndarray, detection: Dict):
        """Dibujar detecci√≥n YOLO del ojo"""
        x1, y1, x2, y2 = detection['x1'], detection['y1'], detection['x2'], detection['y2']
        conf = detection['conf']
        
        # Rect√°ngulo de detecci√≥n
        cv2.rectangle(vis_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        
        # Etiqueta con confianza
        label = f"RIGHT EYE {conf:.2f}"
        cv2.putText(vis_frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
    def _draw_eye_masks(self, vis_frame: np.ndarray, detection: Dict, masks: List):
        """Dibujar m√°scaras de procesamiento dentro del ROI del ojo"""
        x1, y1, x2, y2 = detection['x1'], detection['y1'], detection['x2'], detection['y2']
        roi_w, roi_h = x2 - x1, y2 - y1
        
        for i, (mask, color, label) in enumerate(masks):
            if mask is not None and mask.size > 0:
                # Verificar si es imagen o m√°scara
                if len(mask.shape) == 3:
                    # Es una imagen BGR, usar directamente
                    mask_colored = mask
                else:
                    # Es una m√°scara de un canal, convertir
                    mask_resized = cv2.resize(mask, (roi_w, roi_h))
                    mask_colored = np.zeros((roi_h, roi_w, 3), dtype=np.uint8)
                    mask_colored[mask_resized > 128] = color
                
                # Redimensionar si es necesario
                if mask_colored.shape[:2] != (roi_h, roi_w):
                    mask_colored = cv2.resize(mask_colored, (roi_w, roi_h))
                
                # Aplicar overlay en la regi√≥n del ojo
                eye_roi = vis_frame[y1:y2, x1:x2]
                if eye_roi.shape[:2] == mask_colored.shape[:2]:
                    blended = cv2.addWeighted(eye_roi, 0.7, mask_colored, 0.3, 0)
                    vis_frame[y1:y2, x1:x2] = blended
                
                # Etiqueta de la m√°scara (fuera del ROI)
                label_y = y2 + 20 + (i * 15)
                cv2.putText(vis_frame, label, (x1, label_y), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
                
    def _draw_pupil_detection_improved(self, vis_frame: np.ndarray, detection: Dict, 
                                      pupil_x: float, pupil_y: float, radius: float):
        """Dibujar punto y c√≠rculo de pupila detectada"""
        x1, y1 = detection['x1'], detection['y1']
        
        # Convertir coordenadas locales a globales
        global_pupil_x = int(x1 + pupil_x)
        global_pupil_y = int(y1 + pupil_y)
        
        # Dibujar c√≠rculo de pupila con el radio calculado
        cv2.circle(vis_frame, (global_pupil_x, global_pupil_y), int(radius), (0, 0, 255), 1)
        
        # Punto central
        cv2.circle(vis_frame, (global_pupil_x, global_pupil_y), 2, (0, 255, 0), -1)
        
        # Cruz para marcar el centro
        longitud_cruz = 5
        cv2.line(vis_frame, (global_pupil_x - longitud_cruz, global_pupil_y), 
                (global_pupil_x + longitud_cruz, global_pupil_y), (0, 255, 0), 1)
        cv2.line(vis_frame, (global_pupil_x, global_pupil_y - longitud_cruz), 
                (global_pupil_x, global_pupil_y + longitud_cruz), (0, 255, 0), 1)
        
        # Coordenadas de pupila
        cv2.putText(vis_frame, f"PUPIL ({pupil_x:.0f},{pupil_y:.0f}) R:{radius:.0f}", 
                   (global_pupil_x + 5, global_pupil_y - 5), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
                   
    def _draw_parameters_info(self, vis_frame: np.ndarray):
        """Mostrar informaci√≥n de par√°metros en pantalla"""
        # Fondo semi-transparente para mejor legibilidad
        overlay = vis_frame.copy()
        cv2.rectangle(overlay, (5, 5), (250, 100), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, vis_frame, 0.3, 0, vis_frame)
        
        # Texto de par√°metros
        threshold = self.thresholds.get('threshold_right', 50)
        erode = self.thresholds.get('erode_right', 2)
        nose_width = self.thresholds.get('nose_width', 0.25)
        eye_height = self.thresholds.get('eye_height', 0.5)
        
        cv2.putText(vis_frame, f"Threshold: {threshold}", (10, 25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(vis_frame, f"Erode: {erode}", (10, 45), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(vis_frame, f"Nose Width: {nose_width:.2f}", (10, 65), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(vis_frame, f"Eye Height: {eye_height:.2f}", (10, 85), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
    def _draw_no_detection_info(self, vis_frame: np.ndarray, message: str):
        """Mostrar informaci√≥n cuando no hay detecci√≥n"""
        cv2.putText(vis_frame, message, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
        
    def _draw_error_info(self, vis_frame: np.ndarray, error_msg: str):
        """Mostrar informaci√≥n de error"""
        cv2.putText(vis_frame, f"ERROR: {error_msg}", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        
    def update_thresholds(self, new_thresholds: Dict):
        """Actualizar umbrales de procesamiento"""
        self.thresholds.update(new_thresholds)
        
    def set_visualization_options(self, **options):
        """Configurar opciones de visualizaci√≥n"""
        for key, value in options.items():
            if hasattr(self, key):
                setattr(self, key, value)